{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3cdd03f0-bd92-41dc-903a-2b1fe96ec2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll import all the tools we need at the very beginning.\n",
    "import pandas as pd \n",
    "# for making our visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "# for splitting data\n",
    "from sklearn.model_selection import train_test_split \n",
    "# for turning text into number\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# for fixing our class imbalance \n",
    "from imblearn.over_sampling import SMOTE \n",
    "# we will test two diffrent models\n",
    "from sklearn.naive_bayes import MultinomialNB # A classic, effective model for text\n",
    "from sklearn.linear_model import LogisticRegression # A powerful and common classifier\n",
    "# evaluating our model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2efb9d17-a7c1-4694-ae98-43ddf0435361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ffa9b5f-51d0-4272-b781-c5a101be6eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Head (After Cleaning) ---\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "# we use encoding = 'latin-1' cause this dataset contain special charecter\n",
    "try:\n",
    "    df = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'spam.csv' not found. Make sure it's in the same folder.\")\n",
    "  \n",
    "\n",
    "# keeping only the two column which we need 'v1' (label) and 'v2' (message)\n",
    "df = df[['v1', 'v2']]\n",
    "\n",
    "# Rename the columns to something easy to understand\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "print(\"--- Data Head (After Cleaning) ---\")\n",
    "print(df.head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "059dab4c-b1c4-49f4-a41e-cd47944fd6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "28249a26-eb9b-4f0f-afce-14078f2b6bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Check\n",
      "label      0\n",
      "message    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Class Balance\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Data with 'label_num' (0=ham, 1=spam) ---\n",
      "  label                                            message  label_num\n",
      "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
      "1   ham                      Ok lar... Joking wif u oni...          0\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
      "3   ham  U dun say so early hor... U c already then say...          0\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...          0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking for missing value\n",
    "print(\"Missing Value Check\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Checking the class balance (this is \"imbalance\" problem)\n",
    "print(\"Class Balance\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Creating a new column label_num\n",
    "# machine learning models need numbers not text ('ham' or 'spam').\n",
    "# we will map 'ham' to 0 and 'spam' to 1.\n",
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# this is our new column\n",
    "print(\"--- Data with 'label_num' (0=ham, 1=spam) ---\")\n",
    "print(df.head(5))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7d4f2152-764a-45f2-bb0c-8e406469d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Augmenting Data with Expanded List ---\n",
      "Original shape: (5572, 3)\n",
      "Original value counts:\n",
      " label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- After Expanded Augmenting ---\n",
      "New augmented shape: (5591, 3)\n",
      "\n",
      "New value counts:\n",
      " label\n",
      "ham     4825\n",
      "spam     766\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Augment the data set \n",
    "\n",
    "print(\"--- Augmenting Data with Expanded List ---\")\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Original value counts:\\n\", df['label'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 1. Create a large, diverse list of new scam messages\n",
    "new_spam_messages = [\n",
    "    # Bank / Money Scams\n",
    "    \"Hey, my money accidently transfeered on ur bank\",\n",
    "    \"this is bank wala your account frozen\",\n",
    "    \"URGENT wrong transfer send back plz\",\n",
    "    \"accidently sent money to you, plz return\",\n",
    "    \"u have recvd money from bank wala\",\n",
    "    \"Your bank account has been locked. Please verify immediately.\",\n",
    "    \"A large payment was just sent from your acct. If not you, call now.\",\n",
    "    \"Unusual activity detected on your bank account. Secure it now.\",\n",
    "    \n",
    "    # login \\ password scam\n",
    "    \"Your password has expired. Click here to reset: [link]\",\n",
    "    \"Someone from a new location tried to login to your account.\",\n",
    "    \"Verify your account details now or your account will be suspended.\",\n",
    "    \"Security Alert: Your passwrd has been compromised. Update now.\",\n",
    "    \n",
    "    # Impersonation / Authority Scams\n",
    "    \"Myname is bank wala urgent call me\",\n",
    "    \"This is the security department. We need to verify your details.\",\n",
    "    \"Official notice: Your account is frozen.\",\n",
    "    \n",
    "    # General typos& Urgency\n",
    "    \"acct blocked plz contact me\",\n",
    "    \"need help my money gone\",\n",
    "    \"call me now urgent issue\",\n",
    "    \"plz send back money wrong acct\"\n",
    "]\n",
    "\n",
    "# 2. Create the labels for them (all are 'spam', which is 1)\n",
    "new_labels = ['spam'] * len(new_spam_messages)\n",
    "new_label_nums = [1] * len(new_spam_messages)\n",
    "\n",
    "# 3. Create a new DataFrame from our new data\n",
    "new_data = {\n",
    "    'label': new_labels,\n",
    "    'message': new_spam_messages,\n",
    "    'label_num': new_label_nums\n",
    "}\n",
    "new_spam_df = pd.DataFrame(new_data)\n",
    "\n",
    "# 4. Concatenate (join) our original 'df' with our 'new_spam_df'\n",
    "# This creates our final, complete dataset\n",
    "df_augmented = pd.concat([df, new_spam_df], ignore_index=True)\n",
    "\n",
    "# 5. Check our work!\n",
    "print(\"--- After Expanded Augmenting ---\")\n",
    "print(\"New augmented shape:\", df_augmented.shape)\n",
    "print(\"\\nNew value counts:\\n\", df_augmented['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83ce9d70-4eb6-4365-bc4e-6414b28ba754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now seperating features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cce199e5-eee0-4e4b-bab2-15bb652036a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in our new dataset: 5591\n"
     ]
    }
   ],
   "source": [
    "# We MUST use our new 'df_augmented' DataFrame from now on\n",
    "\n",
    "# X is our 'feature' - the data we use to make predictions\n",
    "X = df_augmented['message']\n",
    "\n",
    "# y is our 'target' - what we *want* to predict\n",
    "y = df_augmented['label_num']\n",
    "\n",
    "print(f\"Total samples in our new dataset: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f1655b5e-d7c5-44c7-a2e2-1bbcd46143e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4472\n",
      "Testing samples: 1119\n"
     ]
    }
   ],
   "source": [
    "# --- [ 6 ] SPLIT DATA INTO TRAINING AND TESTING SETS ---\n",
    "\n",
    "# We split our data:\n",
    "# 80% will be 'training' data\n",
    "# 20% will be 'testing' data\n",
    "# stratify=y is VERY important. It makes sure both the train and test \n",
    "# sets have the same *percentage* of spam/ham.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.20, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7a349431-2e84-4eea-99a5-e417f46dc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # vectorize the text (TF-IDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cade2cca-1942-4e24-aa07-910ef425e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to turn the text messages into a matrix of numbers.\n",
    "# stop_words='english' tells it to ignore common words like 'the', 'is', 'in', etc.\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# First, we 'fit' and 'transform' the training data.\n",
    "# This builds its vocabulary *including our new spam words*.\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# For the test data, we ONLY 'transform' it.\n",
    "# We use the *same* vocabulary it learned from the training data.\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5c8c984a-af8c-42f9-8e9c-8af3332e06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix imbalance with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d28ad66d-de65-42d6-96da-076be19a3def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Applying SMOTE to fix imbalance ---\n",
      "Shape before SMOTE: (4472, 7467)\n",
      "Shape after SMOTE: (7718, 7467)\n",
      "\n",
      "New training set balance:\n",
      "label_num\n",
      "0    3859\n",
      "1    3859\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We apply SMOTE *only* to our training data.\n",
    "print(\"--- Applying SMOTE to fix imbalance ---\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Let's check the new balance of our *training* data\n",
    "print(\"Shape before SMOTE:\", X_train_tfidf.shape)\n",
    "print(\"Shape after SMOTE:\", X_train_resampled.shape)\n",
    "print(\"\\nNew training set balance:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c020bed-e381-410e-84d6-bdbeb5bf758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  train and evaluate model - 1 (Multinomial Naive Bayes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7da35ec4-8573-4ff2-ae8f-6a173ec1d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "   TRAINING: MULTINOMIAL NAIVE BAYES\n",
      "========================================\n",
      "--- Naive Bayes Model training complete! ---\n",
      "\n",
      "========================================\n",
      "   EVALUATION: MULTINOMIAL NAIVE BAYES\n",
      "========================================\n",
      "\n",
      "--- Confusion Matrix (Naive Bayes) ---\n",
      "[[942  24]\n",
      " [ 10 143]]\n",
      "\n",
      "--- Classification Report (Naive Bayes) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.99      0.98      0.98       966\n",
      "    Spam (1)       0.86      0.93      0.89       153\n",
      "\n",
      "    accuracy                           0.97      1119\n",
      "   macro avg       0.92      0.95      0.94      1119\n",
      "weighted avg       0.97      0.97      0.97      1119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*40)\n",
    "print(\"   TRAINING: MULTINOMIAL NAIVE BAYES\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Initialize the model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train the model on our new, balanced, augmented data\n",
    "nb_model.fit(X_train_resampled, y_train_resampled)\n",
    "print(\"--- Naive Bayes Model training complete! ---\\n\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "print(\"=\"*40)\n",
    "print(\"   EVALUATION: MULTINOMIAL NAIVE BAYES\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Make predictions on the *original* unseen test data\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# 1. The Confusion Matrix\n",
    "print(\"\\n--- Confusion Matrix (Naive Bayes) ---\")\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "print(cm_nb)\n",
    "\n",
    "# 2. The Classification Report\n",
    "print(\"\\n--- Classification Report (Naive Bayes) ---\")\n",
    "print(classification_report(y_test, y_pred_nb, target_names=['Ham (0)', 'Spam (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8c571090-3e22-4cd5-99e1-f9b6518bd260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate model  - 2 (Logistic Regression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a9fd6885-7d50-49bf-bec3-af42f35f91f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "   TRAINING: LOGISTIC REGRESSION\n",
      "========================================\n",
      "--- Logistic Regression Model training complete! ---\n",
      "\n",
      "========================================\n",
      "   EVALUATION: LOGISTIC REGRESSION\n",
      "========================================\n",
      "\n",
      "--- Confusion Matrix (Logistic Regression) ---\n",
      "[[962   4]\n",
      " [ 16 137]]\n",
      "\n",
      "--- Classification Report (Logistic Regression) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.98      1.00      0.99       966\n",
      "    Spam (1)       0.97      0.90      0.93       153\n",
      "\n",
      "    accuracy                           0.98      1119\n",
      "   macro avg       0.98      0.95      0.96      1119\n",
      "weighted avg       0.98      0.98      0.98      1119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*40)\n",
    "print(\"   TRAINING: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Initialize the model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the *same* resampled data\n",
    "lr_model.fit(X_train_resampled, y_train_resampled)\n",
    "print(\"--- Logistic Regression Model training complete! ---\\n\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "print(\"=\"*40)\n",
    "print(\"   EVALUATION: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Make predictions using the *original* test set\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# 1. The Confusion Matrix\n",
    "print(\"\\n--- Confusion Matrix (Logistic Regression) ---\")\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(cm_lr)\n",
    "\n",
    "# 2. The Classification Report\n",
    "print(\"\\n--- Classification Report (Logistic Regression) ---\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Ham (0)', 'Spam (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "895cd1a3-ee10-460b-a769-678a2ddf46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the models on our tricky message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f0abe3c7-774a-4701-88f8-ef80b76b6243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "   FINAL TEST ON OUR NEWLY TRAINED MODELS\n",
      "==================================================\n",
      "\n",
      "Message: \"Hey, my money accidently transfeered on ur bank\"\n",
      "  -> Naive Bayes Prediction:   HAM\n",
      "  -> Logistic Regression Prediction: SPAM\n",
      "\n",
      "Message: \"Myname is bank wala\"\n",
      "  -> Naive Bayes Prediction:   SPAM\n",
      "  -> Logistic Regression Prediction: SPAM\n",
      "\n",
      "Message: \"Your password has expired. Click here to reset: [link]\"\n",
      "  -> Naive Bayes Prediction:   SPAM\n",
      "  -> Logistic Regression Prediction: SPAM\n",
      "\n",
      "Message: \"hey what time is the meeting tomorrow?\"\n",
      "  -> Naive Bayes Prediction:   HAM\n",
      "  -> Logistic Regression Prediction: HAM\n"
     ]
    }
   ],
   "source": [
    "# Let's use our tricky messages\n",
    "my_tricky_messages = [\n",
    "    \"Hey, my money accidently transfeered on ur bank\", # Should be SPAM\n",
    "    \"Myname is bank wala\",  # Should be SPAM\n",
    "    \"Your password has expired. Click here to reset: [link]\", # Should be SPAM\n",
    "    \"hey what time is the meeting tomorrow?\" # Should be HAM\n",
    "]\n",
    "\n",
    "# 1. Transform the messages\n",
    "my_messages_tfidf = vectorizer.transform(my_tricky_messages)\n",
    "\n",
    "# 2. Get predictions from BOTH models\n",
    "my_pred_nb = nb_model.predict(my_messages_tfidf)\n",
    "my_pred_lr = lr_model.predict(my_messages_tfidf)\n",
    "\n",
    "\n",
    "# 3. Print a clear comparison\n",
    "print(\"=\"*50)\n",
    "print(\"   FINAL TEST ON OUR NEWLY TRAINED MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i in range(len(my_tricky_messages)):\n",
    "    message = my_tricky_messages[i]\n",
    "    \n",
    "    # Naive Bayes prediction\n",
    "    pred_nb = \"SPAM\" if my_pred_nb[i] == 1 else \"HAM\"\n",
    "    \n",
    "    # Logistic Regression prediction\n",
    "    pred_lr = \"SPAM\" if my_pred_lr[i] == 1 else \"HAM\"\n",
    "    \n",
    "    print(f\"\\nMessage: \\\"{message}\\\"\")\n",
    "    print(f\"  -> Naive Bayes Prediction:   {pred_nb}\")\n",
    "    print(f\"  -> Logistic Regression Prediction: {pred_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d8a01370-7392-48d2-b0a1-aed63225376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model on our own messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d4e9547e-2e96-4f57-bcad-ac4bd253c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "       MODEL TEST\n",
      "==================================================\n",
      "\n",
      "Message: \"Hey, I'm at the bank, will call you back in 10.\"\n",
      "  -> Naive Bayes Prediction:   SPAM\n",
      "  -> Logistic Regression Prediction: HAM\n",
      "\n",
      "Message: \"Your package #4582 is out for delivery. Track here: [link]\"\n",
      "  -> Naive Bayes Prediction:   SPAM\n",
      "  -> Logistic Regression Prediction: HAM\n",
      "\n",
      "Message: \"Can you pick up dinner tonight?\"\n",
      "  -> Naive Bayes Prediction:   HAM\n",
      "  -> Logistic Regression Prediction: HAM\n",
      "\n",
      "Message: \"See you at 8\"\n",
      "  -> Naive Bayes Prediction:   HAM\n",
      "  -> Logistic Regression Prediction: HAM\n",
      "\n",
      "Message: \"You won! Click link.\"\n",
      "  -> Naive Bayes Prediction:   SPAM\n",
      "  -> Logistic Regression Prediction: SPAM\n",
      "\n",
      "Message: \"(Delivery Service): Your item is scheduled for delivery, but the shipping address is incomplete. Please confirm your details here to avoid a delay\"\n",
      "  -> Naive Bayes Prediction:   SPAM\n",
      "  -> Logistic Regression Prediction: SPAM\n"
     ]
    }
   ],
   "source": [
    "# e can edit my_message to insert any messages we want to test.\n",
    "my_messages = [\n",
    "    \"Hey, I'm at the bank, will call you back in 10.\", \n",
    "    \"Your package #4582 is out for delivery. Track here: [link]\", \n",
    "    \"Can you pick up dinner tonight?\", \n",
    "    \"See you at 8\",\n",
    "    \"You won! Click link.\",\n",
    "    \"(Delivery Service): Your item is scheduled for delivery, but the shipping address is incomplete. Please confirm your details here to avoid a delay\" \n",
    "]\n",
    "\n",
    "# This part will remain  the same \n",
    "\n",
    "#  Transform the messages\n",
    "my_messages_tfidf = vectorizer.transform(my_messages)\n",
    "\n",
    "# 2. Get predictions from BOTH models\n",
    "my_pred_nb = nb_model.predict(my_messages_tfidf)\n",
    "my_pred_lr = lr_model.predict(my_messages_tfidf)\n",
    "\n",
    "\n",
    "# 3.now we are printing  a clear comparison\n",
    "print(\"=\"*50)\n",
    "print(\"       MODEL TEST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i in range(len(my_messages)):\n",
    "    message = my_messages[i]\n",
    "    \n",
    "    # Naive Bayes prediction\n",
    "    pred_nb = \"SPAM\" if my_pred_nb[i] == 1 else \"HAM\"\n",
    "    \n",
    "    # Logistic Regression prediction\n",
    "    pred_lr = \"SPAM\" if my_pred_lr[i] == 1 else \"HAM\"\n",
    "    \n",
    "    print(f\"\\nMessage: \\\"{message}\\\"\")\n",
    "    print(f\"  -> Naive Bayes Prediction:   {pred_nb}\")\n",
    "    print(f\"  -> Logistic Regression Prediction: {pred_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b45249-ed35-49bc-9681-c97298e4749f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca4aa6-c8ad-435d-94de-b225f8caa2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f92ce0-d646-4641-b22f-2710955e8b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676a6c2-cdf6-4d0a-b83f-b0f84cae8b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b494c05-9cb0-4bed-a9c4-23da7cf37ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c3988-e06f-4945-9b22-61af3d916e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3798287-7d95-4e53-abec-675bcdb7ee74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922d65a-0c1c-4acd-8d98-28004113ec9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a350b-9744-446a-8511-ae55610491a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfec9b-0099-4829-bf9f-3b66abc662f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
